# Models Page - Quick Reference Guide

**Date:** December 1, 2025  
**File Location:** `/home/juan-canfield/Desktop/web-ui/MODELS_PAGE_WALKTHROUGH.md`

## ğŸ“ What Is This?

A complete beginner-friendly guide to the **Models Page** in FineTune Lab - where you manage, deploy, and test LLM models.

---

## ğŸ¯ What You Can Do Here

| Action | Who Can Do It | Purpose |
|--------|---------------|---------|
| **View Models** | Everyone (if logged in) | See all available models |
| **Search Models** | Everyone | Find models by name |
| **Filter Models** | Everyone | Filter by provider or ownership |
| **Add Custom Model** | Authenticated users | Register new models to system |
| **Edit Model** | Model owner | Update settings (API key, temperature, etc.) |
| **Delete Model** | Model owner | Remove a model from system |
| **Deploy Model** | Model owner | Start inference server (vLLM/Ollama) |
| **Stop Server** | Model owner | Shut down running inference server |

---

## ğŸ—ï¸ Page Structure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HEADER: "Model Management"                  â”‚
â”‚ Description: Manage LLM models...           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚ ğŸ” SEARCH BAR                               â”‚
â”‚ Model name search (case-insensitive)        â”‚
â”‚                                             â”‚
â”‚ ğŸ“Š FILTERS                                  â”‚
â”‚ Provider: [All Providers â–¼]                 â”‚
â”‚ Ownership: [All Models â–¼]                   â”‚
â”‚ Count: Showing 4 of 12 models               â”‚
â”‚ [â• Add Model] Button                       â”‚
â”‚                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚ ğŸ“‹ MODEL CARDS (List of models)             â”‚
â”‚                                             â”‚
â”‚ Each card shows:                            â”‚
â”‚ â€¢ Name & Provider                           â”‚
â”‚ â€¢ Capabilities (âš¡ Streaming, ğŸ› ï¸ Tools)   â”‚
â”‚ â€¢ Token limits                              â”‚
â”‚ â€¢ Settings (temperature, top-p)             â”‚
â”‚ â€¢ Ownership (ğŸŒ Global or ğŸ‘¤ Personal)     â”‚
â”‚ â€¢ Server status (ğŸŸ¢ Running or âš« Stopped)  â”‚
â”‚ â€¢ Action buttons (Edit, Delete, Deploy)     â”‚
â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”‘ Key Concepts

### Global Models ğŸŒ
- Pre-configured by the system
- Available to all users
- Cannot edit or delete
- Example: GPT-4, Claude, Gemini

### Personal Models ğŸ‘¤
- Created or configured by you
- Only visible to you
- Full edit/delete permissions
- Can be fine-tuned or custom API models

### Model Providers
- **openai** - OpenAI (GPT models)
- **anthropic** - Anthropic (Claude)
- **google** - Google (Gemini)
- **vllm** - vLLM inference engine
- **ollama** - Ollama local models
- **local** - Other local models

### Server Status
- ğŸŸ¢ **Running** - Server is active, ready for inference
- ğŸŸ¡ **Starting** - Server is initializing
- âš« **Stopped/Not Deployed** - Server not running
- ğŸ”´ **Error** - Server encountered an error

---

## âš¡ Quick Workflows

### Add a New Model (2 minutes)

```
1. Click [â• Add Model] button
2. Fill form:
   â€¢ Name: Your model name
   â€¢ Provider: openai, anthropic, google, vllm, ollama, local
   â€¢ Model ID: Provider's model identifier
   â€¢ (Optional) API Key, context length, temperature defaults
3. Click [Add Model]
4. âœ“ Model appears in list
```

### Edit a Model (1 minute)

```
1. Find your model in the list
2. Click [Edit] button (only visible for your models)
3. Change desired fields
4. Click [Update Model]
5. âœ“ Changes saved
```

### Delete a Model (1 minute)

```
1. Find your model in the list
2. Click [Delete/Trash] button
3. Confirm deletion
4. âœ“ Model removed
```

### Deploy to vLLM (5 minutes)

```
1. Model must be type: vllm, ollama, or local
2. Click [ğŸš€ Deploy] button
3. Set options:
   â€¢ Server Type: vllm or ollama
   â€¢ GPU Memory: 0.8 (80% GPU usage)
   â€¢ Max Length: 8192 (max prompt size)
4. Click [Deploy Server]
5. â³ Server starting... ğŸŸ¡
6. âœ“ Server running ğŸŸ¢
7. Use in Chat page!
```

### Stop a Running Server (1 minute)

```
1. Find model with running server (ğŸŸ¢ Running)
2. Click [â¬› Stop Server] button
3. âœ“ Server stops, frees GPU memory
```

### Search for a Model (30 seconds)

```
1. Type model name in search bar
2. Results update automatically
3. Or use Provider and Ownership filters
```

---

## ğŸ“Š Form Fields Explained

When adding/editing a model, you might see:

| Field | Required? | Example | Notes |
|-------|-----------|---------|-------|
| **Name** | âœ“ | "GPT-4 Turbo" | Display name in list |
| **Provider** | âœ“ | openai | Where model is hosted |
| **Model ID** | âœ“ | gpt-4-turbo-preview | Provider's identifier |
| **API Key** | âœ— | sk-... | Leave blank for global key |
| **Context Length** | âœ— | 128000 | Max input tokens |
| **Max Output** | âœ— | 4096 | Max generation tokens |
| **Temperature** | âœ— | 0.7 | Randomness (0=boring, 2=crazy) |
| **Top-P** | âœ— | 1.0 | Nucleus sampling (0-1) |
| **Streaming** | âœ— | âœ“ | Can stream responses? |
| **Tools** | âœ— | âœ“ | Function calling support? |
| **Vision** | âœ— | âœ“ | Can process images? |

---

## ğŸ› Troubleshooting

### Models Not Loading?
```
âœ“ Check: Are you logged in?
âœ“ Check: Is your internet connected?
âœ“ Try: Refresh page (Ctrl+R)
âœ“ Try: Clear browser cache and cookies
```

### Can't Add Model?
```
âœ“ All required fields filled? (marked with *)
âœ“ Valid values? (temperature 0-2, top-p 0-1)
âœ“ Unique name? (no duplicates)
```

### Deploy Button Disabled?
```
âœ“ Is it your personal model?
âœ“ Is provider set to vllm, ollama, or local?
âœ“ Is server not already running?
```

### Server Won't Start?
```
âœ“ Try: Reduce gpu_memory_utilization to 0.6
âœ“ Try: Increase max_model_len
âœ“ Try: Check if GPU has space (nvidia-smi)
```

---

## ğŸ”— Related Pages

- **Chat** (`/chat`) - Use deployed models for conversations
- **Training** (`/training`) - Fine-tune models and deploy them
- **Settings** (`/settings`) - Configure global API keys
- **Inference Servers** (deployment management)

---

## ğŸ“š Full Documentation

For detailed explanations, code examples, and advanced workflows, see:
**`MODELS_PAGE_WALKTHROUGH.md`** (3000+ lines)

Covers:
- Complete user journey
- Every workflow step-by-step
- API endpoints and data structures
- Code examples and debugging
- End-to-end scenarios

---

## ğŸ“ For New Users

**Typical First Day:**
1. âœ… Log in
2. âœ… View pre-configured global models
3. âœ… Try searching/filtering
4. âœ… Add a custom OpenAI model (if you have API key)
5. âœ… Deploy a model to vLLM
6. âœ… Test in Chat page

**Typical Daily Use:**
```
Morning:
â†’ Check models page to see what's available
â†’ Deploy specific model for today's work

During Day:
â†’ Use model in Chat page for testing
â†’ Monitor server performance

End of Day:
â†’ Stop server to free resources
```

---

## âœ¨ Pro Tips

1. **Use meaningful names** - "Claude-Customer-Service" vs "Model2"
2. **Set sensible defaults** - Most users like temperature 0.7
3. **Enable streaming** - Faster perceived response time
4. **Test in Chat** - Before using in batch operations
5. **Stop servers** - When not using, saves GPU memory
6. **Check status** - ğŸŸ¢ running vs âš« stopped at a glance

---

**Quick Links:**
- Full Guide: `/home/juan-canfield/Desktop/web-ui/MODELS_PAGE_WALKTHROUGH.md`
- Training Guide: `/home/juan-canfield/Desktop/web-ui/CLOUD_TRAINING_DEPLOYMENT_WORKFLOW.md`

**Last Updated:** December 1, 2025

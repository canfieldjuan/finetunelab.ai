import { NextRequest, NextResponse } from 'next/server';
import { createClient } from '@supabase/supabase-js';
import { detectAnomalies } from '@/lib/services/anomaly-detection.service';

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL!;
const supabaseAnonKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!;

export async function POST(req: NextRequest) {
  try {
    // Authentication
    const authHeader = req.headers.get('authorization');
    if (!authHeader) {
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
    }

    const supabase = createClient(supabaseUrl, supabaseAnonKey, {
      global: { headers: { Authorization: authHeader } },
    });

    const { data: { user }, error: authError } = await supabase.auth.getUser();
    if (authError || !user) {
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
    }

    // Fetch data for the last 24 hours
    const oneDayAgo = new Date(Date.now() - 24 * 60 * 60 * 1000).toISOString();

    // Fetch trace data for the last 24 hours
    const { data: traces, error: traceError } = await supabase
      .from('llm_traces')
      .select(`
        id,
        conversation_id,
        span_id,
        trace_id,
        start_time,
        duration_ms,
        ttft_ms,
        tokens_per_second,
        input_tokens,
        output_tokens,
        total_tokens,
        cache_read_input_tokens,
        cost_usd,
        retrieval_latency_ms,
        rag_relevance_score,
        context_tokens,
        queue_time_ms,
        inference_time_ms,
        status,
        error_category,
        operation_type,
        model_name,
        model_provider
      `)
      .eq('user_id', user.id)
      .gte('start_time', oneDayAgo)
      .not('duration_ms', 'is', null)
      .order('start_time', { ascending: true });

    if (traceError) throw traceError;

    // Type-safe traces array
    type TraceData = {
      id: string;
      conversation_id: string | null;
      span_id: string;
      trace_id: string;
      start_time: string;
      duration_ms: number | null;
      ttft_ms: number | null;
      tokens_per_second: number | null;
      input_tokens: number | null;
      output_tokens: number | null;
      total_tokens: number | null;
      cache_read_input_tokens: number | null;
      cost_usd: number | null;
      retrieval_latency_ms: number | null;
      rag_relevance_score: number | null;
      context_tokens: number | null;
      queue_time_ms: number | null;
      inference_time_ms: number | null;
      status: string | null;
      error_category: string | null;
      operation_type: string | null;
      model_name: string | null;
      model_provider: string | null;
    };
    const typedTraces = (traces as TraceData[]) || [];

    // 1. Duration Analysis (replaces latency_ms)
    const durationPoints = typedTraces
      .filter(t => t.duration_ms)
      .map(t => ({
        timestamp: t.start_time,
        value: t.duration_ms || 0,
        metadata: {
          trace_id: t.trace_id,
          span_id: t.span_id,
          operation_type: t.operation_type,
          conversation_id: t.conversation_id
        }
      }));

    const durationAnomalies = await detectAnomalies(
      durationPoints,
      'duration_ms',
      { zScoreThreshold: 3 }
    );

    // 2. TTFT Analysis (NEW - streaming first token delay)
    const ttftPoints = typedTraces
      .filter(t => t.ttft_ms)
      .map(t => ({
        timestamp: t.start_time,
        value: t.ttft_ms || 0,
        metadata: {
          trace_id: t.trace_id,
          model_name: t.model_name,
          conversation_id: t.conversation_id
        }
      }));

    const ttftAnomalies = await detectAnomalies(
      ttftPoints,
      'ttft_ms',
      { zScoreThreshold: 3 }
    );

    // 3. Throughput Analysis (NEW - tokens/second degradation)
    const throughputPoints = typedTraces
      .filter(t => t.tokens_per_second)
      .map(t => ({
        timestamp: t.start_time,
        value: t.tokens_per_second || 0,
        metadata: {
          trace_id: t.trace_id,
          model_name: t.model_name,
          conversation_id: t.conversation_id
        }
      }));

    const throughputAnomalies = await detectAnomalies(
      throughputPoints,
      'tokens_per_second',
      { zScoreThreshold: 3 }
    );

    // 4. Token Usage Analysis (enhanced with cache awareness)
    const tokenPoints = typedTraces.map(t => ({
      timestamp: t.start_time,
      value: (t.input_tokens || 0) + (t.output_tokens || 0),
      metadata: {
        trace_id: t.trace_id,
        cache_read: t.cache_read_input_tokens,
        conversation_id: t.conversation_id
      }
    }));

    const tokenAnomalies = await detectAnomalies(
      tokenPoints,
      'total_tokens',
      { zScoreThreshold: 3 }
    );

    // 5. Cache Miss Analysis (NEW - cache hit rate)
    const cacheMissPoints = typedTraces
      .filter(t => t.cache_read_input_tokens !== null)
      .map(t => ({
        timestamp: t.start_time,
        value: t.cache_read_input_tokens === 0 ? 1 : 0,
        metadata: {
          trace_id: t.trace_id,
          model_name: t.model_name,
          conversation_id: t.conversation_id
        }
      }));

    const cacheMissAnomalies = await detectAnomalies(
      cacheMissPoints,
      'cache_hit_rate',
      { zScoreThreshold: 3 }
    );

    // 6. Cost Analysis (NEW - cost per request)
    const costPoints = typedTraces
      .filter(t => t.cost_usd !== null)
      .map(t => ({
        timestamp: t.start_time,
        value: t.cost_usd || 0,
        metadata: {
          trace_id: t.trace_id,
          model_name: t.model_name,
          conversation_id: t.conversation_id
        }
      }));

    const costAnomalies = await detectAnomalies(
      costPoints,
      'cost_usd',
      { zScoreThreshold: 3 }
    );

    // 7. RAG Latency Analysis (NEW - retrieval latency)
    const ragLatencyPoints = typedTraces
      .filter(t => t.retrieval_latency_ms !== null)
      .map(t => ({
        timestamp: t.start_time,
        value: t.retrieval_latency_ms || 0,
        metadata: {
          trace_id: t.trace_id,
          model_name: t.model_name,
          conversation_id: t.conversation_id
        }
      }));

    const ragLatencyAnomalies = await detectAnomalies(
      ragLatencyPoints,
      'retrieval_latency_ms',
      { zScoreThreshold: 3 }
    );

    // 8. RAG Relevance Analysis (NEW - relevance score)
    const ragRelevancePoints = typedTraces
      .filter(t => t.rag_relevance_score !== null)
      .map(t => ({
        timestamp: t.start_time,
        value: t.rag_relevance_score || 0,
        metadata: {
          trace_id: t.trace_id,
          model_name: t.model_name,
          conversation_id: t.conversation_id
        }
      }));

    const ragRelevanceAnomalies = await detectAnomalies(
      ragRelevancePoints,
      'rag_relevance_score',
      { zScoreThreshold: 3 }
    );

    // 9. Context Bloat Analysis (NEW - context token usage)
    const contextBloatPoints = typedTraces
      .filter(t => t.context_tokens !== null)
      .map(t => ({
        timestamp: t.start_time,
        value: t.context_tokens || 0,
        metadata: {
          trace_id: t.trace_id,
          model_name: t.model_name,
          conversation_id: t.conversation_id
        }
      }));

    const contextBloatAnomalies = await detectAnomalies(
      contextBloatPoints,
      'context_tokens',
      { zScoreThreshold: 3 }
    );

    // 10. Queue Time Analysis (NEW - queue wait time)
    const queueTimePoints = typedTraces
      .filter(t => t.queue_time_ms !== null)
      .map(t => ({
        timestamp: t.start_time,
        value: t.queue_time_ms || 0,
        metadata: {
          trace_id: t.trace_id,
          model_provider: t.model_provider,
          conversation_id: t.conversation_id
        }
      }));

    const queueTimeAnomalies = await detectAnomalies(
      queueTimePoints,
      'queue_time_ms',
      { zScoreThreshold: 3 }
    );

    // Group anomalies with their metric names
    const anomalyGroups = [
      { name: 'duration_ms', anomalies: durationAnomalies },
      { name: 'ttft_ms', anomalies: ttftAnomalies },
      { name: 'tokens_per_second', anomalies: throughputAnomalies },
      { name: 'total_tokens', anomalies: tokenAnomalies },
      { name: 'cache_hit_rate', anomalies: cacheMissAnomalies },
      { name: 'cost_usd', anomalies: costAnomalies },
      { name: 'retrieval_latency_ms', anomalies: ragLatencyAnomalies },
      { name: 'rag_relevance_score', anomalies: ragRelevanceAnomalies },
      { name: 'context_tokens', anomalies: contextBloatAnomalies },
      { name: 'queue_time_ms', anomalies: queueTimeAnomalies }
    ];

    const savedAnomalies = [];
    let totalDetected = 0;

    for (const group of anomalyGroups) {
      totalDetected += group.anomalies.length;

      for (const anomaly of group.anomalies) {
        const traceId = anomaly.metadata?.trace_id;
        const modelName = anomaly.metadata?.model_name;
        const operationType = anomaly.metadata?.operation_type;
        const conversationId = anomaly.metadata?.conversation_id;

        const { data, error } = await supabase
          .from('anomaly_detections')
          .insert({
            user_id: user.id,
            anomaly_type: anomaly.type,
            severity: anomaly.severity,
            confidence_score: anomaly.confidence,
            metric_name: group.name,
            model_id: modelName,
            conversation_id: conversationId,
            detected_value: anomaly.detectedValue,
            expected_value: (anomaly.expectedRange.lower + anomaly.expectedRange.upper) / 2,
            threshold_value: anomaly.expectedRange.upper,
            deviation_percentage: anomaly.deviation,
            statistics: {
              expectedRange: anomaly.expectedRange,
              confidence: anomaly.confidence,
              trace_id: traceId,
              operation_type: operationType
            },
            description: anomaly.description,
            contributing_factors: anomaly.contributingFactors,
            recommended_actions: anomaly.recommendedActions,
            resolution_status: 'pending',
            acknowledged: false,
            detected_at: new Date().toISOString()
          })
          .select()
          .single();

        if (!error && data) {
          savedAnomalies.push(data);
        }
      }
    }

    return NextResponse.json({
      success: true,
      analyzed_traces: traces?.length || 0,
      anomaly_types_analyzed: 10,
      anomalies_detected: totalDetected,
      anomalies_saved: savedAnomalies.length,
      breakdown: {
        duration: durationAnomalies.length,
        ttft: ttftAnomalies.length,
        throughput: throughputAnomalies.length,
        tokens: tokenAnomalies.length,
        cache_miss: cacheMissAnomalies.length,
        cost: costAnomalies.length,
        rag_latency: ragLatencyAnomalies.length,
        rag_relevance: ragRelevanceAnomalies.length,
        context_bloat: contextBloatAnomalies.length,
        queue_time: queueTimeAnomalies.length
      }
    });

  } catch (error) {
    console.error('[Anomaly API] Error:', error);
    return NextResponse.json(
      { error: error instanceof Error ? error.message : 'Internal Server Error' },
      { status: 500 }
    );
  }
}
import fs from 'fs';
import path from 'path';

const OLLAMA_URL = 'http://localhost:11434';
const EMBEDDING_MODEL = 'nomic-embed-text'; // Run: ollama pull nomic-embed-text

async function generateEmbedding(text: string) {
  const response = await fetch(`${OLLAMA_URL}/api/embeddings`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      model: EMBEDDING_MODEL,
      prompt: text,
    }),
  });

  if (!response.ok) {
    throw new Error(`Ollama API error: ${response.statusText}`);
  }

  const data = await response.json();
  return data.embedding; // Array of numbers (vectors)
}

async function main() {
  console.log(`ğŸ”Œ Connecting to Ollama at ${OLLAMA_URL}`);
  console.log(`ğŸ§  Using model: ${EMBEDDING_MODEL}`);

  // Example: Embed this script itself
  const filePath = __filename;
  const content = fs.readFileSync(filePath, 'utf-8');
  
  console.log(`\nğŸ“„ Processing file: ${path.basename(filePath)}`);
  console.log(`ğŸ“ Content length: ${content.length} characters`);

  try {
    console.time('Embedding Generation');
    const vector = await generateEmbedding(content);
    console.timeEnd('Embedding Generation');

    console.log(`\nâœ… Success! Generated vector with ${vector.length} dimensions.`);
    console.log(`ğŸ“Š First 5 dimensions: ${JSON.stringify(vector.slice(0, 5))}`);
    console.log(`\nğŸ’¡ Next Step: Store this vector in Supabase (pgvector) with the file path.`);
  } catch (error) {
    console.error('âŒ Error:', error);
    console.log('ğŸ‘‰ Tip: Make sure you ran "ollama pull nomic-embed-text"');
  }
}

main();